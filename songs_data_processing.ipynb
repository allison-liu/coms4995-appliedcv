{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5721a5-f73e-49c6-a4fd-d1c2044abb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file will just be data processing loool \n",
    "# maybe put info into csv file (song title,song artist,mood1,mood2,...)\n",
    "\n",
    "# for every file in millionsongsubset, we need to get the songs\n",
    "# for every song, we need to webscrape allmusic to find the moods\n",
    "\n",
    "# can download a subset by using wget and a url from the million song database website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b22e13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# imports?\n",
    "# pip install tables\n",
    "# pip install pyquery\n",
    "# pip install fuzzywuzzy\n",
    "# pip install selenium\n",
    "import tarfile\n",
    "import os\n",
    "import hdf5_getters\n",
    "import numpy as np\n",
    "import csv\n",
    "import allmusic_scraping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from seleniumbase import Driver\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2e5ac9-c59e-49c2-83bc-9e1f86330624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract msd data\n",
    "def extract_tar_gz(file_path, extract_path):\n",
    "    # Open the tar.gz file\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        # Extract all files\n",
    "        tar.extractall(path=extract_path)\n",
    "\n",
    "# Example usage:\n",
    "tar_gz_file = 'millionsongsubset.tar.gz'\n",
    "extract_directory = 'millionsongsubset'\n",
    "\n",
    "# Make sure the extract directory exists\n",
    "os.makedirs(extract_directory, exist_ok=True)\n",
    "\n",
    "# Extract the tar.gz file\n",
    "extract_tar_gz(tar_gz_file, extract_directory)\n",
    "\n",
    "# after extracting the file, flatten the directories with this terminal call:\n",
    "# $ find coms4995-appliedcv/millionsongsubset/MillionSongSubset -type f -exec mv -i '{}' ./coms4995-appliedcv/millionsongsubset \\;\n",
    "\n",
    "# now remove the folder with the redundant files\n",
    "# $ cd coms4995-appliedcv/millionsongsubset/\n",
    "# $ rm -r MillionSongSubset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c203d3e0-a504-4e64-a065-167c8e58213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a csv file (song title,song artist,mood1,mood2,...)\n",
    "def read_moods(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        moods = []\n",
    "        moods_dict = {}\n",
    "        count = 0\n",
    "        for line in file:\n",
    "            m = line.strip().lower()\n",
    "            moods.append(m)\n",
    "            moods_dict[m] = count\n",
    "            count += 1\n",
    "        return moods, moods_dict\n",
    "        #return [line.strip() for line in file]\n",
    "\n",
    "# moods.txt from https://github.com/fdlm/listening-moods/blob/master/data/moods.txt\n",
    "moods_file = 'moods.txt'\n",
    "\n",
    "# Read moods from file\n",
    "moods, moods_dict = read_moods(moods_file)\n",
    "\n",
    "# Headers contain song title, song artist, and moods\n",
    "headers = ['song_title', 'song_artist'] + moods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decab848-80b1-411e-9e5c-c6209d2cb313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"hello\"\n",
    "x[:x.index('l')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495e555-cbd8-4260-839a-afd5977c4382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside scraper dirty dancer   michael white\n",
      "https://www.allmusic.com/song/dirty-dancer-mt0004502108#moodsThemes\n",
      "didn't find moods\n",
      "inside scraper everywhere  michelle tumes\n",
      "https://www.allmusic.com/song/everywhere-mt0005074330#moodsThemes\n",
      "didn't find moods\n",
      "inside scraper finding my way stanley clarke & george duke\n",
      "https://www.allmusic.com/song/finding-my-way-mt0053351035#moodsThemes\n",
      "didn't find moods\n",
      "inside scraper de tha mai edo domna kountouri\n",
      "https://www.allmusic.com/song/de-tha-mai-edo-mt0016871171#moodsThemes\n",
      "didn't find moods\n",
      "inside scraper sally can't dance lou reed\n",
      "https://www.allmusic.com/song/sally-cant-dance-mt0006125722#moodsThemes\n",
      "['brooding', 'confident', 'greasy', 'gritty', 'gutsy', 'nocturnal', 'passionate', 'reflective', 'sophisticated', 'street-smart', 'swaggering', 'lively']\n",
      "inside scraper my fofo   fat joe\n",
      "https://www.allmusic.com/song/my-fofo-mt0039479117#moodsThemes\n",
      "didn't find moods\n",
      "inside scraper it must be love  rickie lee jones\n",
      "https://www.allmusic.com/song/it-must-be-love-mt0005180582#moodsThemes\n",
      "['exuberant', 'joyous', 'warm']\n",
      "inside scraper new pony bob dylan\n",
      "https://www.allmusic.com/song/new-pony-mt0008597571#moodsThemes\n",
      "['laid-back/mellow', 'lazy', 'literate', 'relaxed', 'rousing', 'swaggering']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lazy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 89\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# go through mood_words and one hot encode it in data\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mood \u001b[38;5;129;01min\u001b[39;00m mood_words:\n\u001b[0;32m---> 89\u001b[0m         song_data[\u001b[43mmoods_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmood\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lazy'"
     ]
    }
   ],
   "source": [
    "# Directory containing the .h5 files\n",
    "directory = './millionsongsubset'\n",
    "data = []\n",
    "num_moods = len(moods)\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file is an .h5 file\n",
    "    if filename.endswith('.h5'):\n",
    "        # Process the .h5 file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # print(f\"Processing file: {file_path}\")\n",
    "        # process the .h5 file\n",
    "        h5 = hdf5_getters.open_h5_file_read(file_path)\n",
    "        num_songs = hdf5_getters.get_num_songs(h5)\n",
    "        \n",
    "        for i in range(num_songs):\n",
    "            song_data = []\n",
    "            song_title = hdf5_getters.get_title(h5,i)\n",
    "            song_title = song_title.decode('utf-8').lower()\n",
    "            \n",
    "            try:\n",
    "                parentheses = song_title.index('(')\n",
    "            except ValueError:\n",
    "                parentheses = -1\n",
    "            \n",
    "            if parentheses != -1:\n",
    "                song_title = song_title[:parentheses]\n",
    "                \n",
    "            song_artist = hdf5_getters.get_artist_name(h5,i)\n",
    "            song_artist = song_artist.decode('utf-8').lower()\n",
    "            \n",
    "            song_data.append(song_title)\n",
    "            song_data.append(song_artist)\n",
    "            \n",
    "            song_data += [0]*num_moods\n",
    "            \n",
    "            # song_search_matching\n",
    "            # https://github.com/jack-arms/allmusic-python/blob/master/allmusic.py\n",
    "            # query: chart_song.title + ' ' + main_artist\n",
    "            # print(song_title)\n",
    "            # print(song_artist)\n",
    "            allmusic_song = allmusic_scraping.song_search(song_title + ' ' + song_artist, 3)\n",
    "            # print(allmusic_song)\n",
    "            # find mood for the song\n",
    "            # check if there was an error during the search\n",
    "            if isinstance(allmusic_song, dict) and 'error' in allmusic_song:\n",
    "                print(\"Error:\", allmusic_song['error'])\n",
    "                continue # throw error?\n",
    "\n",
    "            # check if any search results were found\n",
    "            if not allmusic_song:\n",
    "                print(\"No search results found for the given query.\")\n",
    "                continue # throw error?\n",
    "\n",
    "            top_result = allmusic_song[0]\n",
    "\n",
    "            # get html url\n",
    "            html_page_url = top_result['title']['url'] + \"#moodsThemes\"\n",
    "\n",
    "            # fetch html\n",
    "            if html_page_url:\n",
    "                print(html_page_url)\n",
    "                html_page = requests.get(html_page_url)\n",
    "                html_page = requests.get(html_page_url, headers={\n",
    "                    'Host': 'www.allmusic.com',\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "                    'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "                    'Accept-Language': 'en-US,en;q=0.8'\n",
    "                })\n",
    "                driver = Driver(browser=\"chrome\", headless=False)\n",
    "                \n",
    "                driver.get(html_page_url)\n",
    "                \n",
    "                try:\n",
    "                    try:\n",
    "                        scraped_moods = WebDriverWait(driver, 2).until(\n",
    "                            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div#moodsGrid > div > a'))\n",
    "                        )\n",
    "                    except TimeoutException:\n",
    "                        print(\"didn't find moods\")\n",
    "                        continue\n",
    "                    \n",
    "                    mood_words = [m.text[:m.text.index(' ')].lower() for m in scraped_moods]\n",
    "                    print(mood_words)\n",
    "                    # go through mood_words and one hot encode it in data\n",
    "                    for mood in mood_words:\n",
    "                        if mood in moods_dict:\n",
    "                            song_data[moods_dict[mood]+2] = 1\n",
    "                    \n",
    "                finally:\n",
    "                    driver.quit()\n",
    "\n",
    "#                 if html_page.status_code == 200:\n",
    "#                     soup = BeautifulSoup(html_page.text, 'html.parser')\n",
    "#                     # iframes = soup.find_all('iframe')\n",
    "#                     # # print(html_page.text)\n",
    "#                     mood_grid_div = soup.find_all('div', {'id':'moodsGrid'})\n",
    "#                     # # print(mood_grid_div)\n",
    "                    \n",
    "#                     # Use PyQuery to parse the HTML content\n",
    "#                     # d = pq(html_page.text)\n",
    "#                     # Find the div with id 'moodsGrid'\n",
    "#                     # mood_grid_div = d('div#moodsGrid')\n",
    "\n",
    "#                     # mood_grid_div = d('div#moodsGrid')\n",
    "#                     # mood_grid_div = d.xpath('//div[@id=\"moodsGrid\"]')\n",
    "#                     # mood_grid_div = d('/html/body/div[1]/div/section/div[2]/div[8]/div[2]/div[1]')\n",
    "#                     print(type(mood_grid_div))\n",
    "#                     print(mood_grid_div)\n",
    "#                     if mood_grid_div:\n",
    "#                         # find all 'a' tags within the 'moodGrid' div\n",
    "#                         a_tags = mood_grid_div.find('a')\n",
    "#                         print(\"a_tags\", a_tags)\n",
    "#                         # get text from each 'a' tag\n",
    "#                         mood_words = [a_tag.text for a_tag in a_tags]\n",
    "#                         print(mood_words)\n",
    "#                         # go through mood_words and one hot encode it in data\n",
    "#                         for mood in mood_words:\n",
    "#                             song_data[moods_dict[mood]+2] = 1\n",
    "#                     else:\n",
    "#                         continue # no moods found.. don't add to data?\n",
    "#                 else:\n",
    "#                     print(\"Failed to fetch HTML page:\", html_page.status_code)\n",
    "            else:\n",
    "                print(\"No URL found for the top search result.\")\n",
    "            \n",
    "            data.append(song_data)\n",
    "            \n",
    "        h5.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88e8384-1fef-4083-8b95-a8b83661993e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acerbic': 0,\n",
       " 'aggressive': 1,\n",
       " 'agreeable': 2,\n",
       " 'ambitious': 3,\n",
       " 'amiable/good-natured': 4,\n",
       " 'angry': 5,\n",
       " 'angst-ridden': 6,\n",
       " 'anguished/distraught': 7,\n",
       " 'animated': 8,\n",
       " 'atmospheric': 9,\n",
       " 'austere': 10,\n",
       " 'autumnal': 11,\n",
       " 'belligerent': 12,\n",
       " 'bitter': 13,\n",
       " 'bittersweet': 14,\n",
       " 'bleak': 15,\n",
       " 'boisterous': 16,\n",
       " 'brash': 17,\n",
       " 'brassy': 18,\n",
       " 'bravado': 19,\n",
       " 'bright': 20,\n",
       " 'brittle': 21,\n",
       " 'brooding': 22,\n",
       " 'calm/peaceful': 23,\n",
       " 'campy': 24,\n",
       " 'carefree': 25,\n",
       " 'cathartic': 26,\n",
       " 'celebratory': 27,\n",
       " 'cerebral': 28,\n",
       " 'cheerful': 29,\n",
       " 'circular': 30,\n",
       " 'clinical': 31,\n",
       " 'cold': 32,\n",
       " 'complex': 33,\n",
       " 'confident': 34,\n",
       " 'confrontational': 35,\n",
       " 'crunchy': 36,\n",
       " 'cynical/sarcastic': 37,\n",
       " 'delicate': 38,\n",
       " 'detached': 39,\n",
       " 'difficult': 40,\n",
       " 'dramatic': 41,\n",
       " 'dreamy': 42,\n",
       " 'driving': 43,\n",
       " 'druggy': 44,\n",
       " 'earnest': 45,\n",
       " 'earthy': 46,\n",
       " 'eccentric': 47,\n",
       " 'eerie': 48,\n",
       " 'effervescent': 49,\n",
       " 'elaborate': 50,\n",
       " 'elegant': 51,\n",
       " 'energetic': 52,\n",
       " 'enigmatic': 53,\n",
       " 'epic': 54,\n",
       " 'ethereal': 55,\n",
       " 'exciting': 56,\n",
       " 'exuberant': 57,\n",
       " 'fierce': 58,\n",
       " 'fiery': 59,\n",
       " 'flowing': 60,\n",
       " 'fractured': 61,\n",
       " 'freewheeling': 62,\n",
       " 'fun': 63,\n",
       " 'gentle': 64,\n",
       " 'giddy': 65,\n",
       " 'gleeful': 66,\n",
       " 'gloomy': 67,\n",
       " 'greasy': 68,\n",
       " 'gritty': 69,\n",
       " 'gutsy': 70,\n",
       " 'happy': 71,\n",
       " 'harsh': 72,\n",
       " 'hedonistic': 73,\n",
       " 'hostile': 74,\n",
       " 'humorous': 75,\n",
       " 'hypnotic': 76,\n",
       " 'indulgent': 77,\n",
       " 'innocent': 78,\n",
       " 'insular': 79,\n",
       " 'intense': 80,\n",
       " 'intimate': 81,\n",
       " 'introspective': 82,\n",
       " 'ironic': 83,\n",
       " 'irreverent': 84,\n",
       " 'joyous': 85,\n",
       " 'knotty': 86,\n",
       " 'laid-back/mellow': 87,\n",
       " 'light': 88,\n",
       " 'literate': 89,\n",
       " 'lively': 90,\n",
       " 'lush': 91,\n",
       " 'malevolent': 92,\n",
       " 'manic': 93,\n",
       " 'meandering': 94,\n",
       " 'melancholy': 95,\n",
       " 'melodic': 96,\n",
       " 'menacing': 97,\n",
       " 'messy': 98,\n",
       " 'naive': 99,\n",
       " 'nihilistic': 100,\n",
       " 'nocturnal': 101,\n",
       " 'nostalgic': 102,\n",
       " 'ominous': 103,\n",
       " 'optimistic': 104,\n",
       " 'organic': 105,\n",
       " 'outrageous': 106,\n",
       " 'paranoid': 107,\n",
       " 'passionate': 108,\n",
       " 'pastoral': 109,\n",
       " 'plaintive': 110,\n",
       " 'playful': 111,\n",
       " 'poignant': 112,\n",
       " 'positive': 113,\n",
       " 'powerful': 114,\n",
       " 'precious': 115,\n",
       " 'provocative': 116,\n",
       " 'quirky': 117,\n",
       " 'rambunctious': 118,\n",
       " 'ramshackle': 119,\n",
       " 'raucous': 120,\n",
       " 'rebellious': 121,\n",
       " 'reckless': 122,\n",
       " 'refined': 123,\n",
       " 'reflective': 124,\n",
       " 'relaxed': 125,\n",
       " 'reserved': 126,\n",
       " 'restrained': 127,\n",
       " 'reverent': 128,\n",
       " 'rollicking': 129,\n",
       " 'romantic': 130,\n",
       " 'rousing': 131,\n",
       " 'rowdy': 132,\n",
       " 'rustic': 133,\n",
       " 'sad': 134,\n",
       " 'searching': 135,\n",
       " 'self-conscious': 136,\n",
       " 'sensual': 137,\n",
       " 'sentimental': 138,\n",
       " 'sexual': 139,\n",
       " 'sexy': 140,\n",
       " 'silly': 141,\n",
       " 'sleazy': 142,\n",
       " 'slick': 143,\n",
       " 'smooth': 144,\n",
       " 'snide': 145,\n",
       " 'soft/quiet': 146,\n",
       " 'somber': 147,\n",
       " 'soothing': 148,\n",
       " 'sophisticated': 149,\n",
       " 'spacey': 150,\n",
       " 'sparkling': 151,\n",
       " 'sparse': 152,\n",
       " 'spicy': 153,\n",
       " 'spiritual': 154,\n",
       " 'spooky': 155,\n",
       " 'sprawling': 156,\n",
       " 'springlike': 157,\n",
       " 'stately': 158,\n",
       " 'street-smart': 159,\n",
       " 'strong': 160,\n",
       " 'stylish': 161,\n",
       " 'suffocating': 162,\n",
       " 'sugary': 163,\n",
       " 'summery': 164,\n",
       " 'swaggering': 165,\n",
       " 'sweet': 166,\n",
       " 'tender': 167,\n",
       " 'tense/anxious': 168,\n",
       " 'theatrical': 169,\n",
       " 'thoughtful': 170,\n",
       " 'tough': 171,\n",
       " 'trashy': 172,\n",
       " 'trippy': 173,\n",
       " 'uncompromising': 174,\n",
       " 'unsettling': 175,\n",
       " 'uplifting': 176,\n",
       " 'urgent': 177,\n",
       " 'visceral': 178,\n",
       " 'volatile': 179,\n",
       " 'warm': 180,\n",
       " 'weary': 181,\n",
       " 'whimsical': 182,\n",
       " 'wintry': 183,\n",
       " 'wistful': 184,\n",
       " 'witty': 185,\n",
       " 'wry': 186,\n",
       " 'yearning': 187}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moods_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4718177e-b321-49bc-9ac2-caed72a5001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(file_path, data, headers):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(headers)\n",
    "        for row in data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aeda7f5-0f70-4a49-8507-38ac98314cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"sally can't dance\",\n",
       "  'lou reed',\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " ['it must be love ',\n",
       "  'rickie lee jones',\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a71768-b196-425d-acaa-38309fc689e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_csv = 'song_moods.csv'\n",
    "\n",
    "# Write to CSV\n",
    "write_csv(song_csv, data, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da739b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all the files in /millionsongsubset\n",
    "# for each file, find the songs in allmusic.com (id=\"moodsGrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597bd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each song in msd, webscrape allmusic for moods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e4ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find spotify id for song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba340dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store in dictionary {mood: [spotify id]}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
